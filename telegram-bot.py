#!/usr/bin/env python3
"""
Telegram Bot –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Mini App "listen.sound.reflect.create"
"""

import os
import asyncio
import logging
from datetime import datetime
from typing import Optional

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters
from supabase import create_client, Client
from openai import OpenAI
import requests

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)
BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_ANON_KEY')
WEBAPP_URL = os.getenv('WEBAPP_URL', 'https://listen-sound-reflect-create.vercel.app/')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
OPENAI_ASSISTANT_ID = os.getenv('OPENAI_ASSISTANT_ID')

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
openai_client: OpenAI | None = None
if OPENAI_API_KEY:
    try:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        if OPENAI_ASSISTANT_ID:
            logger.info(f"‚úÖ OpenAI Assistant initialized: {OPENAI_ASSISTANT_ID[:20]}...")
        else:
            logger.warning("‚ö†Ô∏è OPENAI_ASSISTANT_ID not set")
    except Exception as e:
        logger.error(f"Failed to initialize OpenAI: {e}")

class AudioHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
    
    @staticmethod
    async def download_audio(bot, file_id: str) -> bytes:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏–∑ Telegram"""
        try:
            file = await bot.get_file(file_id)
            return await file.download_as_bytearray()
        except Exception as e:
            logger.error(f"Failed to download audio: {e}")
            raise
    
    @staticmethod
    async def upload_to_supabase(audio_data: bytes, user_id: int, audio_type: str) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ –≤ Supabase Storage"""
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            timestamp = datetime.now().isoformat().replace(':', '-')
            file_name = f"{audio_type}_{user_id}_{timestamp}.ogg"
            file_path = f"audio/{file_name}"
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Storage
            result = supabase.storage.from_("audio").upload(
                file_path, 
                audio_data,
                file_options={"content-type": "audio/ogg"}
            )
            
            if result.error:
                raise Exception(f"Upload error: {result.error}")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—É–±–ª–∏—á–Ω—ã–π URL
            public_url = supabase.storage.from_("audio").get_public_url(file_path)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –ë–î
            db_result = supabase.table('audio_files').insert({
                'file_name': file_name,
                'file_path': file_path,
                'file_url': public_url.data.get('publicUrl'),
                'file_size': len(audio_data),
                'mime_type': 'audio/ogg',
                'audio_type': audio_type,
                'user_id': str(user_id),
                'created_at': datetime.now().isoformat()
            }).execute()
            
            return {
                'file_name': file_name,
                'public_url': public_url.data.get('publicUrl'),
                'audio_file_id': db_result.data[0]['id'] if db_result.data else None
            }
            
        except Exception as e:
            logger.error(f"Failed to upload to Supabase: {e}")
            raise

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user = update.effective_user
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å Mini App
    keyboard = [
        [InlineKeyboardButton(
            "üéµ Open Mini App", 
            web_app={"url": WEBAPP_URL}
        )],
        [InlineKeyboardButton(
            "‚ÑπÔ∏è About Deep Listening", 
            callback_data="about"
        )]
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É —á–∞—Ç–∞ —Å Assistant, –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω
    if OPENAI_ASSISTANT_ID and openai_client:
        keyboard.append([InlineKeyboardButton(
            "üí¨ Chat with Assistant",
            callback_data="start_chat"
        )])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    welcome_text = f"""
üéµ *Welcome to Listen.Sound.Reflect.Create*

Hello {user.first_name}! This bot helps you explore Deep Listening practices inspired by Pauline Oliveros.

*How it works:*
‚Ä¢ Open the Mini App to start a session
‚Ä¢ Follow the Listen ‚Üí Sound ‚Üí Reflect ‚Üí Create flow
‚Ä¢ Send voice messages when prompted
‚Ä¢ Your audio will be saved and processed

*Ready to begin your sonic journey?*
"""
    
    await update.message.reply_text(
        welcome_text,
        parse_mode='Markdown',
        reply_markup=reply_markup
    )

async def about_callback(update: Update, context) -> None:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ Deep Listening"""
    query = update.callback_query
    await query.answer()
    
    about_text = """
üéº *About Deep Listening*

Deep Listening is a practice developed by composer Pauline Oliveros. It involves:

‚Ä¢ *Listening* to the environment around you
‚Ä¢ *Sounding* in response to what you hear  
‚Ä¢ *Reflecting* on the experience
‚Ä¢ *Creating* new sonic possibilities

This practice enhances awareness, creativity, and connection with sound environments.

*"Deep Listening is listening in every possible way to everything possible to hear no matter what you are doing."* - Pauline Oliveros
"""
    
    keyboard = [[InlineKeyboardButton("üéµ Start Session", web_app={"url": WEBAPP_URL})]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.edit_message_text(
        about_text,
        parse_mode='Markdown',
        reply_markup=reply_markup
    )

async def handle_voice_message(update: Update, context) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user = update.effective_user
    voice = update.message.voice
    
    try:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        processing_msg = await update.message.reply_text("üé§ Processing your audio...")
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ
        audio_data = await AudioHandler.download_audio(context.bot, voice.file_id)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞—É–¥–∏–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'reflection')
        audio_type = 'reflection'  # –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Supabase
        result = await AudioHandler.upload_to_supabase(audio_data, user.id, audio_type)
        
        # –£–≤–µ–¥–æ–º–ª—è–µ–º –æ–± —É—Å–ø–µ—Ö–µ
        success_text = f"""
‚úÖ *Audio saved successfully!*

üìÅ File: `{result['file_name']}`
üîó URL: [Listen]({result['public_url']})
üíæ Size: {len(audio_data)} bytes

Your audio is now part of your Deep Listening journey.
"""
        
        keyboard = [[InlineKeyboardButton("üéµ Continue in Mini App", web_app={"url": WEBAPP_URL})]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await processing_msg.edit_text(
            success_text,
            parse_mode='Markdown',
            reply_markup=reply_markup
        )
        
    except Exception as e:
        logger.error(f"Voice processing error: {e}")
        await update.message.reply_text(
            "‚ùå Sorry, there was an error processing your audio. Please try again."
        )

async def handle_audio_message(update: Update, context) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
    # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –≥–æ–ª–æ—Å–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏—è–º
    await handle_voice_message(update, context)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–º–æ—â—å"""
    help_text = """
üéµ *Listen.Sound.Reflect.Create Bot*

*Commands:*
‚Ä¢ `/start` - Begin your Deep Listening journey
‚Ä¢ `/chat` - Chat with Assistant about Deep Listening
‚Ä¢ `/help` - Show this help message

*How to use:*
1. Open the Mini App to start a session
2. Follow the guided experience
3. Send voice messages when prompted
4. Your audio will be automatically saved

*Voice Messages:*
Send voice messages anytime to save them as part of your sonic exploration.

*Need help?* The Mini App will guide you through each step of the Deep Listening process.
"""
    
    keyboard = [[InlineKeyboardButton("üéµ Open Mini App", web_app={"url": WEBAPP_URL})]]
    if OPENAI_ASSISTANT_ID and openai_client:
        keyboard.append([InlineKeyboardButton("üí¨ Chat with Assistant", callback_data="start_chat")])
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        help_text,
        parse_mode='Markdown',
        reply_markup=reply_markup
    )

async def chat_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /chat –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å Assistant"""
    user_id = update.effective_user.id
    
    if not OPENAI_ASSISTANT_ID or not openai_client:
        await update.message.reply_text(
            "‚ö†Ô∏è Assistant –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –î–æ–±–∞–≤—å—Ç–µ OPENAI_API_KEY –∏ OPENAI_ASSISTANT_ID –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è."
        )
        return
    
    # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º —á–∞—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if 'user_sessions' not in context.bot_data:
        context.bot_data['user_sessions'] = {}
    if user_id not in context.bot_data['user_sessions']:
        context.bot_data['user_sessions'][user_id] = {}
    context.bot_data['user_sessions'][user_id]['chat_mode'] = True
    
    logger.info(f"‚úÖ Chat mode enabled for user {user_id} via /chat command")
    
    await update.message.reply_text(
        "üí¨ –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –æ Deep Listening, –∏ —è –ø–µ—Ä–µ–¥–∞–º –µ–≥–æ –º–æ–µ–º—É Assistant."
    )

async def chat_with_assistant(user_text: str) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ OpenAI Assistant –∏ –ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç."""
    if not openai_client or not OPENAI_ASSISTANT_ID:
        return "‚ö†Ô∏è Assistant –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
    
    try:
        loop = asyncio.get_event_loop()
        
        # –°–æ–∑–¥–∞–µ–º thread –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
        thread = await loop.run_in_executor(
            None,
            lambda: openai_client.beta.threads.create()
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await loop.run_in_executor(
            None,
            lambda: openai_client.beta.threads.messages.create(
                thread_id=thread.id,
                role="user",
                content=user_text
            )
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º Assistant
        run = await loop.run_in_executor(
            None,
            lambda: openai_client.beta.threads.runs.create(
                thread_id=thread.id,
                assistant_id=OPENAI_ASSISTANT_ID
            )
        )
        
        # –ñ–¥–µ–º –æ—Ç–≤–µ—Ç–∞ (–º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥)
        timeout = 60
        elapsed = 0
        while run.status in ['queued', 'in_progress'] and elapsed < timeout:
            await asyncio.sleep(2)
            elapsed += 2
            
            run = await loop.run_in_executor(
                None,
                lambda: openai_client.beta.threads.runs.retrieve(
                    thread_id=thread.id,
                    run_id=run.id
                )
            )
        
        if run.status == 'completed':
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç—ã –æ—Ç Assistant
            messages = await loop.run_in_executor(
                None,
                lambda: openai_client.beta.threads.messages.list(
                    thread_id=thread.id,
                    order="asc"
                )
            )
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç assistant
            for message in reversed(messages.data):
                if message.role == 'assistant':
                    content = message.content[0] if message.content else None
                    if content and hasattr(content, 'text'):
                        return content.text.value
            
            return "‚ùå –û—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç Assistant"
        else:
            logger.error(f"Assistant run failed: {run.status}")
            return f"‚ùå –û—à–∏–±–∫–∞: {run.status}"
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å Assistant: {e}", exc_info=True)
        return f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"

async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = update.effective_user.id
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ —á–∞—Ç–∞ —Å Assistant
    if context.bot_data.get('user_sessions', {}).get(user_id, {}).get('chat_mode', False):
        user_text = update.message.text
        logger.info(f"üí¨ Chat mode activated for user {user_id}: {user_text[:50]}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞–±–æ—Ä–∞
        thinking_msg = await update.message.reply_text("ü§î –î—É–º–∞—é...")
        
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Assistant
            assistant_response = await chat_with_assistant(user_text)
            logger.info(f"‚úÖ Assistant response received for user {user_id}")
            
            # –£–¥–∞–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
            await thinking_msg.delete()
            await update.message.reply_text(assistant_response)
            
            # –°–ø—Ä–∞—à–∏–≤–∞–µ–º, —Ö–æ—á–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
            keyboard = InlineKeyboardMarkup([
                [InlineKeyboardButton("üí¨ –ó–∞–¥–∞—Ç—å –µ—â–µ –≤–æ–ø—Ä–æ—Å", callback_data="continue_chat")],
                [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
            ])
            await update.message.reply_text(
                "–•–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –∏–ª–∏ –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é?",
                reply_markup=keyboard
            )
        except Exception as e:
            logger.error(f"‚ùå Error in chat_with_assistant for user {user_id}: {e}", exc_info=True)
            await thinking_msg.delete()
            await update.message.reply_text(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
    else:
        # –û–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–º–æ—â—å
        await update.message.reply_text(
            "–ü—Ä–∏–≤–µ—Ç! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞ –∏–ª–∏ /help –¥–ª—è –ø–æ–º–æ—â–∏."
        )

async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏"""
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    
    if query.data == "start_chat":
        if not OPENAI_ASSISTANT_ID or not openai_client:
            await query.answer("‚ö†Ô∏è Assistant –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω", show_alert=True)
            return
        
        # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º —á–∞—Ç–∞
        if 'user_sessions' not in context.bot_data:
            context.bot_data['user_sessions'] = {}
        if user_id not in context.bot_data['user_sessions']:
            context.bot_data['user_sessions'][user_id] = {}
        context.bot_data['user_sessions'][user_id]['chat_mode'] = True
        
        logger.info(f"‚úÖ Chat mode enabled for user {user_id} via button")
        
        await query.edit_message_text(
            "üí¨ –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –æ Deep Listening, –∏ —è –ø–µ—Ä–µ–¥–∞–º –µ–≥–æ –º–æ–µ–º—É Assistant."
        )
    
    elif query.data == "continue_chat":
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∂–∏–º —á–∞—Ç–∞
        if 'user_sessions' not in context.bot_data:
            context.bot_data['user_sessions'] = {}
        if user_id not in context.bot_data['user_sessions']:
            context.bot_data['user_sessions'][user_id] = {}
        context.bot_data['user_sessions'][user_id]['chat_mode'] = True
        
        await query.edit_message_text(
            "üí¨ –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –æ Deep Listening:"
        )
    
    elif query.data == "main_menu":
        # –í—ã–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º —á–∞—Ç–∞
        if 'user_sessions' in context.bot_data and user_id in context.bot_data['user_sessions']:
            context.bot_data['user_sessions'][user_id]['chat_mode'] = False
        
        keyboard = [
            [InlineKeyboardButton("üéµ Open Mini App", web_app={"url": WEBAPP_URL})],
            [InlineKeyboardButton("‚ÑπÔ∏è About Deep Listening", callback_data="about")]
        ]
        
        if OPENAI_ASSISTANT_ID and openai_client:
            keyboard.append([InlineKeyboardButton("üí¨ Chat with Assistant", callback_data="start_chat")])
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        welcome_text = f"""
üéµ *Welcome to Listen.Sound.Reflect.Create*

Hello {query.from_user.first_name}! This bot helps you explore Deep Listening practices.

*Ready to begin your sonic journey?*
"""
        await query.edit_message_text(
            welcome_text,
            parse_mode='Markdown',
            reply_markup=reply_markup
        )

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    if not BOT_TOKEN:
        logger.error("TELEGRAM_BOT_TOKEN not set!")
        return
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        logger.error("Supabase credentials not set!")
        return
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(BOT_TOKEN).build()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("chat", chat_command))
    application.add_handler(CallbackQueryHandler(button_handler))
    application.add_handler(CallbackQueryHandler(about_callback, pattern="about"))
    application.add_handler(MessageHandler(filters.VOICE, handle_voice_message))
    application.add_handler(MessageHandler(filters.AUDIO, handle_audio_message))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    logger.info("Starting bot...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
